---
title: "Lab 10 - Point and Interval Estimates"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Lab 10 - Maximum Likelihood Estimation}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
fig_width: 6 
fig_height: 4
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>",
  fig.width = 6,
  fig.height = 4,
  fig.align = "center"
)
```

```{r setup}
library(MATH4753ROSAlab10)
```

# Introduction

This package produces point and interval estimates from a variety of different functions. Point and interval estimates are a very important part of classical and Bayesian statistics. In this vignette we will investigate different methods of making point and interval estimates according to Maximum Likelihood Theory. That is:

  a. Grid Approximation
  b. Newton-Raphson Method
  c. Algebraic First Principals
  
Though, we will forego the latter in this package. Throughout this vignette, we will utilize various log-likelihood functions as "support" or "helper" functions to the heavy-weight functions that this package is most concerned with.

# `mymaxlik`

We will look at two examples of this function using different distributions: Binomial and Poisson.

## Binomial

```{r}
logbin <- function(x,param) log(dbinom(x, prob = param, size = 20))

v <- mymaxlik(x=c(9,10,11),
         param=seq(0,1,length=1000),
         lfun=logbin,
         xlab=expression(pi),
         main="Binomial",
         cex.main=1)

v
```

## Poisson

```{r}
logpoiss <- function(x,param) log(dpois(x,lambda = param))

k <- mymaxlik(x = c(5,5,6,7),
              param=seq(0,100,length=1000),
              lfun=logpoiss,
              xlab=expression(lambda),
              main="Poisson",
              cex.main=2
              )
k
```

For both functions, the returned list:

* `i` is the index for the value of $x$ which maximizes the function parameter, $p$.

* `parami`, at the end, becomes the value of the parameter which we seek

* `yi` is a vector of column [enter appropriate function here], and $y_i$ is the value in the "`ith`" location of the vector.

* `slope` is a vector of slope values, note it contains three positive values and two non-positive ones.

# `mymld`

```{r}
logpoiss = function(x,param) log(dpois(x,lambda=param)) 

l <- mymld(x = c(5,5,6,7),
           param=seq(0,100,length=1000),
           lfun=logpoiss
           )
l
```

This is a more accurate version of the previous previous function. The returned value indicates the value of the desired parameter (label $\theta$ here) which _approximately_ gives the maximum.

# `mymaxlikg`

```{r}
 mymaxlikg(theta=seq(0,1,length=10000))
```

This function is more general. You can use a grid approximation to make maximum likelihood estimations, provided you create the appropriate helper function (in the example `logbin2()`)

> Note: we can now use independent binomials with different $n$ values assuming the same $p$.

> Also note: the plot is the likelihood not log-likelihood.

# `mymlnorm`

```{r}
xx <- mymlnorm(x=c(5,7,7,8,10),
               mu=seq(5,10,length=1000),
               sig=seq(0.1,4,length=1000),
               lwd=2,
               labcex=1,
               col = "darkgreen"
               )
xx
```

My personal favorite function from this package, `mymlnorm` enables us to find the maximum likelihood estimates for $\mu$ and $\sigma$ when the data are distributed Normally. From the returned list:

* `x` returns the value(s) of $x$ which were inputs for the function.

* `muest` is the estimated parameter $\mu$.

* `sigest` is the estimated parameter $\sigma$.

* `maxl` is the "$y$" value of the maximum likelihood; note it is close to $0$.

# `mynewt`, `myNewnewt`, and `myNRML`

All of these functions do _essentially_ the same thing. The latter two, however, find the derivative internally. Note: the `myNEWnewt` function was my original take on writing a function that indeed finds the derivative internally (I am rather proud I did it!)

I will for brevity, use the `myNRML` function.

```{r}
ans6 <- myNRML(x0=0.05,
               delta=0.000001,
               llik=function(x) log(dpois(3,lambda = x)*dpois(4,lambda = x)),
               xrange=c(0,1),
               parameter="lambda")

ans6
```

The output shows that the $y's$ get infinitesimal as $x$ approaches the MLE.

# `myboot`

The final function in this package utilizes the theory of bootstrapping and re-sampling.

```{r}
set.seed(39); sam=rnorm(25,mean=25,sd=10)

a7 <- myboot(10000,x=sam,fun="mean",alpha=0.05,xlab="mean",col="pink",cx=1.5) # mac quartz()

a7
```

The output gives us a confidence interval! 

